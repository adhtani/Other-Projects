{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2: Sentiment Analysis\n",
    "\n",
    "#### DSC 550\n",
    "\n",
    "Taniya Adhikari 1/10/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\taniy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from re import sub\n",
    "import multiprocessing\n",
    "from unidecode import unidecode\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "from time import time \n",
    "from collections import defaultdict\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "import textblob\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the data file DailyComments.csv from the Week 4 Data Files into a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Day of Week    7\n",
       "comments       7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"DailyComments.csv\")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Hello, how are you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Today is a good day!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>It's my birthday so it's a really special day!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Today is neither a good day or a bad day!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday</td>\n",
       "      <td>I'm having a bad day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>There' s nothing special happening today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Today is a SUPER good day!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Day of Week                                        comments\n",
       "0      Monday                             Hello, how are you?\n",
       "1     Tuesday                            Today is a good day!\n",
       "2   Wednesday  It's my birthday so it's a really special day!\n",
       "3    Thursday       Today is neither a good day or a bad day!\n",
       "4      Friday                           I'm having a bad day.\n",
       "5    Saturday       There' s nothing special happening today.\n",
       "6      Sunday                      Today is a SUPER good day!"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Pre-processing before modeling for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>comments</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday</td>\n",
       "      <td>hello</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>today good day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>birthday realli special day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>today neither good day bad day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday</td>\n",
       "      <td>im bad day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>noth special happen today</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>today super good day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Day of Week                        comments  stopwords\n",
       "0      Monday                           hello          0\n",
       "1     Tuesday                  today good day          0\n",
       "2   Wednesday     birthday realli special day          0\n",
       "3    Thursday  today neither good day bad day          0\n",
       "4      Friday                      im bad day          0\n",
       "5    Saturday       noth special happen today          0\n",
       "6      Sunday            today super good day          0"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pre_processing(df):\n",
    "    # converting all text to lowercase\n",
    "    df[\"comments\"] = df[\"comments\"].str.lower()\n",
    "    \n",
    "    # removing punctuation using string.punctuations and join()\n",
    "    df[\"comments\"] = df[\"comments\"].apply(lambda x: \"\".join([i for i in x if i not in string.punctuation]))\n",
    "    \n",
    "    # remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "\n",
    "    df['stopwords'] = df[\"comments\"].apply(lambda x: len([i for i in x.split() if i in stop]))\n",
    "    df[\"comments\"]= df[\"comments\"].apply(lambda x: \" \".join(i for i in x.split() if i not in stop))\n",
    "    df['stopwords'] = df['comments'].apply(lambda x: len([i for i in x.split() if i in stop]))\n",
    "    \n",
    "    # stemming\n",
    "    porter = PorterStemmer()\n",
    "    df[\"comments\"] = df[\"comments\"].apply(lambda x: \" \".join([porter.stem(word) for word in x.split()]))\n",
    "    return df\n",
    "\n",
    "df2 = pre_processing(df)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting string into list of words for each comment\n",
    "def text_to_list(text):\n",
    "    pattern = r'[^A-Za-z ]'\n",
    "    regex = re.compile(pattern)\n",
    "    text = regex.sub('', text).split(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>comments</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday</td>\n",
       "      <td>[hello]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>[today, good, day]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>[birthday, realli, special, day]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>[today, neither, good, day, bad, day]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday</td>\n",
       "      <td>[im, bad, day]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Day of Week                               comments  stopwords\n",
       "0      Monday                                [hello]          0\n",
       "1     Tuesday                     [today, good, day]          0\n",
       "2   Wednesday       [birthday, realli, special, day]          0\n",
       "3    Thursday  [today, neither, good, day, bad, day]          0\n",
       "4      Friday                         [im, bad, day]          0"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = df2.copy()\n",
    "clean_df.comments = clean_df.comments.apply(lambda x: text_to_list(x))\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:04:02: collecting all words and their counts\n",
      "INFO - 14:04:02: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 14:04:02: collected 28 word types from a corpus of 25 words (unigram + bigrams) and 7 sentences\n",
      "INFO - 14:04:02: using 28 counts as vocab in Phrases<0 vocab, min_count=1, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 14:04:02: source_vocab length 28\n",
      "INFO - 14:04:02: Phraser built with 0 phrasegrams\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['today', 'super', 'good', 'day']"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extraction of phrases and bigram model\n",
    "sent = [row for row in clean_df.comments]\n",
    "phrases = Phrases(sent, min_count=1, progress_per=7)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sent]\n",
    "sentences[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 14:04:04: consider setting layer size to a multiple of 4 for greater performance\n",
      "INFO - 14:04:04: collecting all words and their counts\n",
      "INFO - 14:04:04: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:04:04: collected 13 word types from a corpus of 25 raw words and 7 sentences\n",
      "INFO - 14:04:04: Loading a fresh vocabulary\n",
      "INFO - 14:04:04: effective_min_count=1 retains 13 unique words (100% of original 13, drops 0)\n",
      "INFO - 14:04:04: effective_min_count=1 leaves 25 word corpus (100% of original 25, drops 0)\n",
      "INFO - 14:04:04: deleting the raw counts dictionary of 13 items\n",
      "INFO - 14:04:04: sample=0.001 downsamples 13 most-common words\n",
      "INFO - 14:04:04: downsampling leaves estimated 3 word corpus (12.1% of prior 25)\n",
      "INFO - 14:04:04: estimated required memory for 13 words and 2 dimensions: 6708 bytes\n",
      "INFO - 14:04:04: resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=1, size=2)\n",
    "\n",
    "# building vocab\n",
    "w2v_model.build_vocab(sentences, progress_per=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:04:04: training model with 3 workers on 13 vocabulary and 2 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 14:04:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:04:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:04:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:04:04: EPOCH - 1 : training on 25 raw words (1 effective words) took 0.0s, 324 effective words/s\n",
      "INFO - 14:04:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:04:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:04:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:04:04: EPOCH - 2 : training on 25 raw words (1 effective words) took 0.0s, 376 effective words/s\n",
      "INFO - 14:04:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:04:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:04:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:04:04: EPOCH - 3 : training on 25 raw words (3 effective words) took 0.0s, 922 effective words/s\n",
      "INFO - 14:04:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:04:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:04:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:04:04: EPOCH - 4 : training on 25 raw words (1 effective words) took 0.0s, 348 effective words/s\n",
      "INFO - 14:04:04: training on a 100 raw words (6 effective words) took 0.0s, 230 effective words/s\n",
      "WARNING - 14:04:04: under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "INFO - 14:04:04: precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=4, report_delay=1)\n",
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=13, size=2, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:04:06: saving Word2Vec object under word2vec.model, separately None\n",
      "INFO - 14:04:06: not storing attribute vectors_norm\n",
      "INFO - 14:04:06: not storing attribute cum_table\n",
      "INFO - 14:04:06: saved word2vec.model\n"
     ]
    }
   ],
   "source": [
    "w2v_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:04:07: loading Word2Vec object from word2vec.model\n",
      "INFO - 14:04:07: loading wv recursively from word2vec.model.wv.* with mmap=None\n",
      "INFO - 14:04:07: setting ignored attribute vectors_norm to None\n",
      "INFO - 14:04:07: loading vocabulary recursively from word2vec.model.vocabulary.* with mmap=None\n",
      "INFO - 14:04:07: loading trainables recursively from word2vec.model.trainables.* with mmap=None\n",
      "INFO - 14:04:07: setting ignored attribute cum_table to None\n",
      "INFO - 14:04:07: loaded word2vec.model\n"
     ]
    }
   ],
   "source": [
    "word_vectors = Word2Vec.load(\"word2vec.model\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means clustering to create two centroids which will later used as positive negative sentiments\n",
    "model = KMeans(n_clusters=2, max_iter=100).fit(X=word_vectors.vectors.astype(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.78832501, -0.0736144 ],\n",
       "       [ 0.61350253,  0.39413982]])"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:04:12: precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('good', 0.9780603647232056),\n",
       " ('hello', 0.9035085439682007),\n",
       " ('super', 0.9016662836074829),\n",
       " ('realli', 0.8192667365074158),\n",
       " ('noth', 0.8170955181121826),\n",
       " ('birthday', 0.7565217614173889),\n",
       " ('day', 0.5820415019989014),\n",
       " ('special', 0.5758768320083618),\n",
       " ('neither', -0.3850495517253876),\n",
       " ('today', -0.45182546973228455)]"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for similarity\n",
    "word_vectors.similar_by_vector(model.cluster_centers_[0], restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = model.cluster_centers_[0]\n",
    "negative = model.cluster_centers_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(word_vectors.vocab.keys())\n",
    "words.columns = ['words']\n",
    "words['vectors'] = words.words.apply(lambda x: word_vectors[f'{x}'])\n",
    "words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
    "words.cluster = words.cluster.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>vectors</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_value</th>\n",
       "      <th>closeness_score</th>\n",
       "      <th>sentiment_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello</td>\n",
       "      <td>[-0.9394416, 0.34270886]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.257841</td>\n",
       "      <td>2.257841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>today</td>\n",
       "      <td>[0.532813, -0.846233]</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.804509</td>\n",
       "      <td>-0.804509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>[-0.95445466, -0.29835606]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.578101</td>\n",
       "      <td>3.578101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>day</td>\n",
       "      <td>[-0.5039158, -0.86375284]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.190808</td>\n",
       "      <td>1.190808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>birthday</td>\n",
       "      <td>[-0.6924411, -0.7214743]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.526911</td>\n",
       "      <td>1.526911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>realli</td>\n",
       "      <td>[-0.86903167, 0.4947565]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.741941</td>\n",
       "      <td>1.741941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>special</td>\n",
       "      <td>[-0.64939374, 0.76045233]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.182650</td>\n",
       "      <td>1.182650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neither</td>\n",
       "      <td>[0.29757416, 0.9546987]</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.554105</td>\n",
       "      <td>-1.554105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bad</td>\n",
       "      <td>[0.63992137, 0.7684404]</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.665019</td>\n",
       "      <td>-2.665019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>im</td>\n",
       "      <td>[0.6566255, 0.7542168]</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.757480</td>\n",
       "      <td>-2.757480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>noth</td>\n",
       "      <td>[-0.75995505, -0.64997566]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.732925</td>\n",
       "      <td>1.732925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>happen</td>\n",
       "      <td>[0.9405786, 0.3395762]</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.015718</td>\n",
       "      <td>-3.015718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>super</td>\n",
       "      <td>[-0.93796647, 0.34672597]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.241237</td>\n",
       "      <td>2.241237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       words                     vectors  cluster  cluster_value  \\\n",
       "0      hello    [-0.9394416, 0.34270886]        0              1   \n",
       "1      today       [0.532813, -0.846233]        1             -1   \n",
       "2       good  [-0.95445466, -0.29835606]        0              1   \n",
       "3        day   [-0.5039158, -0.86375284]        0              1   \n",
       "4   birthday    [-0.6924411, -0.7214743]        0              1   \n",
       "5     realli    [-0.86903167, 0.4947565]        0              1   \n",
       "6    special   [-0.64939374, 0.76045233]        0              1   \n",
       "7    neither     [0.29757416, 0.9546987]        1             -1   \n",
       "8        bad     [0.63992137, 0.7684404]        1             -1   \n",
       "9         im      [0.6566255, 0.7542168]        1             -1   \n",
       "10      noth  [-0.75995505, -0.64997566]        0              1   \n",
       "11    happen      [0.9405786, 0.3395762]        1             -1   \n",
       "12     super   [-0.93796647, 0.34672597]        0              1   \n",
       "\n",
       "    closeness_score  sentiment_coeff  \n",
       "0          2.257841         2.257841  \n",
       "1          0.804509        -0.804509  \n",
       "2          3.578101         3.578101  \n",
       "3          1.190808         1.190808  \n",
       "4          1.526911         1.526911  \n",
       "5          1.741941         1.741941  \n",
       "6          1.182650         1.182650  \n",
       "7          1.554105        -1.554105  \n",
       "8          2.665019        -2.665019  \n",
       "9          2.757480        -2.757480  \n",
       "10         1.732925         1.732925  \n",
       "11         3.015718        -3.015718  \n",
       "12         2.241237         2.241237  "
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words['cluster_value'] = [1 if i==0 else -1 for i in words.cluster]\n",
    "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
    "words['sentiment_coeff'] = words.closeness_score * words.cluster_value\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do a simple sentiment analysis for small data set with few words, I decided to focus on each word's sentiment instead of sentiment_coefficient.\n",
    "\n",
    "Following code, takes word list from each comment, looks up word in words dataframe and retreives cluster_value which is the sentiment of the word. It creates a dictionary with the counts of positive and negative words for each comments and then compares the two values. This returns the sentiment of each comment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer(wordlist):\n",
    "    cluster_count = {}\n",
    "    for w in wordlist:\n",
    "        x = cluster_freq(w, words)\n",
    "        if x in cluster_count:\n",
    "            cluster_count[x] = cluster_count[x] + 1\n",
    "        else:\n",
    "            cluster_count[x] = 1\n",
    "                  \n",
    "    if '-1' in cluster_count.keys() and '1' in cluster_count.keys():\n",
    "        pos = cluster_count.get('1')\n",
    "        neg = cluster_count.get('-1')\n",
    "        if pos >= neg:\n",
    "            sentiment = \"Positive\"\n",
    "        else:\n",
    "            sentiment = \"Negative\"\n",
    "\n",
    "    elif '-1' not in cluster_count.keys() and '1' in cluster_count.keys():\n",
    "        sentiment = \"Positive\"\n",
    "    elif '1' not in cluster_count.keys() and '-1' in cluster_count.keys():\n",
    "        sentiment = \"Negative\"\n",
    "    else:\n",
    "        None\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_freq(word, df):\n",
    "    x = ''\n",
    "    for i, r in df.iterrows():\n",
    "        if r['words'] == word:\n",
    "            x = str(r['cluster_value'])\n",
    "        else:\n",
    "            None\n",
    "    return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code iterate through each row of the df and turn comments into string and then list of words.\n",
    "Further it's passsed to function sentiment_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>comments</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday</td>\n",
       "      <td>hello</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>today good day</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>birthday realli special day</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>today neither good day bad day</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday</td>\n",
       "      <td>im bad day</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>noth special happen today</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>today super good day</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Day of Week                        comments  stopwords sentiment\n",
       "0      Monday                           hello          0  Positive\n",
       "1     Tuesday                  today good day          0  Positive\n",
       "2   Wednesday     birthday realli special day          0  Positive\n",
       "3    Thursday  today neither good day bad day          0  Positive\n",
       "4      Friday                      im bad day          0  Negative\n",
       "5    Saturday       noth special happen today          0  Positive\n",
       "6      Sunday            today super good day          0  Positive"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_count = {}\n",
    "sentiment = []\n",
    "for i, r in df2.iterrows():\n",
    "    comment = r['comments']\n",
    "    wordlist = comment.split()\n",
    "    result = sentiment_analyzer(wordlist)\n",
    "    sentiment.append(result)\n",
    "df2['sentiment'] = sentiment    \n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_func(comments):\n",
    "    pol = TextBlob(comments).sentiment.polarity\n",
    "    if pol >= 0:\n",
    "        x = \"Positive\"\n",
    "    else:\n",
    "        x = \"Negative\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['textblob_sentiment']= df2['comments'].apply(sentiment_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>comments</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday</td>\n",
       "      <td>hello</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>today good day</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>birthday realli special day</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>today neither good day bad day</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday</td>\n",
       "      <td>im bad day</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>noth special happen today</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>today super good day</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Day of Week                        comments  stopwords sentiment  \\\n",
       "0      Monday                           hello          0  Positive   \n",
       "1     Tuesday                  today good day          0  Positive   \n",
       "2   Wednesday     birthday realli special day          0  Positive   \n",
       "3    Thursday  today neither good day bad day          0  Positive   \n",
       "4      Friday                      im bad day          0  Negative   \n",
       "5    Saturday       noth special happen today          0  Positive   \n",
       "6      Sunday            today super good day          0  Positive   \n",
       "\n",
       "  textblob_sentiment  \n",
       "0           Positive  \n",
       "1           Positive  \n",
       "2           Positive  \n",
       "3           Positive  \n",
       "4           Negative  \n",
       "5           Positive  \n",
       "6           Positive  "
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data didn't have sentiment associated with it, so I decided to take unsupervised approach for a small dataset. I used word2vec model, kmeans clustering algorithm and my own algorithm to do my own analysis. For Word2vec we used CBOW architecture code can be found here [myGitHub](https://github.com/adhtani/DSC550/blob/master/Exercise4_TAdhikari.ipynb). I also followed procedure from this tutorial [Unsupervised Sentiment Analysis](https://towardsdatascience.com/unsupervised-sentiment-analysis-a38bf1906483). I created bigrams of words detection and replaced with gensim’s Phrases module (see In [559]) and used that to create word2vec model, further I build a vocabulary and trained the model.\n",
    "\n",
    "These are initial steps before kmeans clustering algorithm. I used sklearn’s K-means algorithm with 100 iterations of reassigning points to clusters and used 2 clusters. I checked with gensim’s most_similar method to see which word vectors are similar to first cluster. I created a df with words and their sentiment coefficient.\n",
    "\n",
    "Furthermore, I created a simple algorithm that will count the positive and negative words in each comments. and assign sentiments based on number of positive and negative words see [571, 572, 573]).\n",
    "I further checked the accuracy based on results from Textblob which is another python library that has a pre-trained dataset and uses Naive bayes classifier to predict sentiment.\n",
    "\n",
    "Results were fairly accurate based on the assigned positive and negative values. However, simple counting good and bad words is not the best approach because sentiment analysis works by looking at the pattern within the data. This will not work when the dataset is big with complex texts such as tweets. In my extra exercise file I tried this method with 20 stocktwits data, and I got inaccurate results. So for the bigger dataset **Tfidf weighting** for sentiment prediction will work better with complex data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
